{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8kHTzZaDNMPn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import losses as lo_ss\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "import string\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import seaborn as snsd\n",
        "from sklearn import model_selection\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import classification_report , roc_auc_score\n",
        "import keras\n",
        "import keras.backend as K\n",
        "from google.colab import drive\n",
        "from numpy import savetxt\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading data from csv file\n",
        "\n",
        "import os\n",
        "github_raw_link=\"https://raw.githubusercontent.com/Aryansh085/LAP/main/858417d1-7d54-4115-a01b-fdda5e03ada3_testing_combined_rows4035_disc_1_0p9_MULTIPLY_preproces_155cols.csv\"\n",
        "df1=pd.read_csv((github_raw_link),header = None)\n",
        "df1=np.array(df1)\n",
        "\n",
        "df1.shape\n",
        "\n",
        "# Making a new dataframe which contains only relevant features\n",
        "df = df1[:,5:]\n",
        "df = np.array(df)\n",
        "\n",
        "# Standardizing data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "slr=StandardScaler()\n",
        "slr.fit(df)\n",
        "df = slr.transform(df)\n",
        "\n",
        "# final dataframe\n",
        "df=pd.DataFrame(df)\n",
        "df.head()\n",
        "\n",
        "# Making 3d array where each row contains last t rows information of the data\n",
        "x = np.array(df)\n",
        "# print(x.shape,y.shape)\n",
        "\n",
        "# timestamp is defined here \n",
        "t = 5\n",
        "\n",
        "# Storing output corresponding to the new dataframe and according to the timestamp\n",
        "y=np.array(df1[:,0])\n",
        "y=y[t:]\n",
        "\n",
        "x_3d = []\n",
        "for i in range(4035-t):\n",
        "  tmp = []\n",
        "  for j in range(t):\n",
        "    tmp.append(x[j+i])\n",
        "  x_3d.append(tmp)\n",
        "x_3d = np.array(x_3d)\n",
        "x_3d.shape\n",
        "\n",
        "# making test and train input and output data for the lstm layer\n",
        "total_size = x_3d.shape[0]\n",
        "\n",
        "# assigning train-test ratio to split data in train-test\n",
        "train_test_ratio=0.8\n",
        "train_size = int(total_size * train_test_ratio)\n",
        "test_size = total_size - train_size"
      ],
      "metadata": {
        "id": "nCHAqI3qNZyS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# these array will contain test and train data\n",
        "x_train, y_train, x_test, y_test = [], [], [], []\n",
        "\n",
        "# Random assignment of data : filling the test and train data randomly\n",
        "for i in range(x_3d.shape[0]):\n",
        "  feature = []\n",
        "  corr_output = []\n",
        "\n",
        "  no = np.random.randint(100)\n",
        "\n",
        "  if(no < 80):\n",
        "    feature = x_3d[i]\n",
        "    corr_output = y[i]\n",
        "\n",
        "    x_train.append(feature) \n",
        "    y_train.append(corr_output) \n",
        "\n",
        "  else:\n",
        "    feature = x_3d[i]\n",
        "    corr_output = y[i]\n",
        "\n",
        "    x_test.append(feature) \n",
        "    y_test.append(corr_output) \n",
        "\n",
        "# changing each to np array\n",
        "main_x_train = np.array(x_train)\n",
        "main_y_train = np.array(y_train)\n",
        "x_test = np.array(x_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "print(main_x_train.shape, main_y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n06Xj7-DNeNL",
        "outputId": "6294801b-36e1-4f9e-d2df-86adf27181d0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3203, 5, 150) (3203,)\n",
            "(827, 5, 150) (827,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saved model importing and predicting through it here"
      ],
      "metadata": {
        "id": "8g6pxWR9N5oC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHv0EPktODkb",
        "outputId": "c5429cbe-6284-4640-afba-58d4559b7dec"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras \n",
        "\n",
        "#import keras backend\n",
        "import keras.backend as K\n",
        "\n",
        "# f1-score function\n",
        "def get_f1(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision + recall + K.epsilon())\n",
        "    return f1_val"
      ],
      "metadata": {
        "id": "zaSR29cDO9nI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model=load_model(\"/content/drive/MyDrive/Colab Notebooks/LAP_project/model.h5\")\n",
        "# model=load_model(\"/content/drive/MyDrive/Colab Notebooks/model.h5\")\n",
        "\n",
        "# output of the model\n",
        "test_output_1 = model.predict(x_test, verbose=1)\n",
        "test_output_1 = np.array([np.argmax(i)  for i in test_output_1])\n",
        "test_output_1.shape\n",
        "\n",
        "# printing confusion matrix and accuracy score\n",
        "print(\"confusion matrix : \\n\", confusion_matrix(y_test,test_output_1))\n",
        "test_output = pd.DataFrame(test_output_1)\n",
        "print(\"accuracy score : \", accuracy_score(y_test,test_output_1))\n",
        "\n",
        "# printing f1-score\n",
        "print(get_f1(y_test.astype('float32'), test_output_1.astype('float32')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1OgusTpOZH5",
        "outputId": "59f7f53f-a8b6-44d7-cc41-995523abe795"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26/26 [==============================] - 5s 135ms/step\n",
            "confusion matrix : \n",
            " [[363  13  12]\n",
            " [ 11 194   1]\n",
            " [  7   5 221]]\n",
            "accuracy score :  0.9407496977025392\n",
            "tf.Tensor(0.95141244, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k = model.predict(x_test[50:80])\n",
        "k"
      ],
      "metadata": {
        "id": "HGh8JAdROn9s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29710960-d5f1-43ca-f017-65f46b2acaa1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 75ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.58994412e-01, 3.84313345e-01, 2.27347583e-01],\n",
              "       [9.48219359e-01, 8.19555763e-03, 1.00790372e-03],\n",
              "       [2.45850682e-02, 9.82402444e-01, 7.44045451e-02],\n",
              "       [6.25645936e-01, 1.67085856e-01, 9.99993980e-01],\n",
              "       [6.35502636e-01, 1.39125362e-01, 9.99998927e-01],\n",
              "       [5.51707804e-01, 2.40523577e-01, 9.99953210e-01],\n",
              "       [4.56615329e-01, 4.15303200e-01, 9.94307578e-01],\n",
              "       [5.73506594e-01, 2.22324729e-01, 9.99963343e-01],\n",
              "       [9.15965438e-01, 1.91051513e-02, 3.47520388e-03],\n",
              "       [8.77600074e-01, 3.74604948e-02, 9.40246787e-03],\n",
              "       [5.78029513e-01, 3.30420583e-01, 9.44004506e-02],\n",
              "       [9.88339663e-01, 6.56305288e-04, 2.58855453e-05],\n",
              "       [9.32153285e-01, 1.31112291e-02, 2.00117403e-03],\n",
              "       [3.31098586e-02, 9.75475669e-01, 8.74338299e-02],\n",
              "       [2.97072437e-02, 9.78314519e-01, 8.34410712e-02],\n",
              "       [7.66608417e-02, 9.28381503e-01, 3.96512866e-01],\n",
              "       [5.00749797e-02, 9.63229537e-01, 1.58110023e-01],\n",
              "       [2.37020124e-02, 9.83214796e-01, 7.48598874e-02],\n",
              "       [9.15873289e-01, 1.91422459e-02, 3.48512619e-03],\n",
              "       [8.89474511e-01, 3.11544314e-02, 7.15038134e-03],\n",
              "       [7.27681756e-01, 8.90917107e-02, 9.99999821e-01],\n",
              "       [5.90921402e-01, 2.18455672e-01, 9.99943912e-01],\n",
              "       [8.32920969e-01, 5.05043343e-02, 1.00000000e+00],\n",
              "       [6.08806074e-01, 1.77686006e-01, 9.99992669e-01],\n",
              "       [9.98978376e-01, 1.15381545e-05, 7.48390079e-08],\n",
              "       [3.07112820e-02, 9.77603853e-01, 8.67308304e-02],\n",
              "       [2.67160591e-02, 9.80752349e-01, 7.91643634e-02],\n",
              "       [2.98780631e-02, 9.78406370e-01, 8.84407610e-02],\n",
              "       [3.21043581e-02, 9.76199985e-01, 8.41995478e-02],\n",
              "       [8.82818818e-01, 3.46197896e-02, 8.36191326e-03]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax(k,axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeGsrCM7dTSI",
        "outputId": "1b7fbfde-05a0-4b32-de7d-6810eec9e1e5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 2, 2, 0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 0, 0, 1, 1, 1, 1, 1,\n",
              "       0, 2, 0, 1, 2, 2, 2, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wd414Z5YdhF2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test[50:80]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oY4_fAEhc7S7",
        "outputId": "aa710a22-ee3f-4444-9f6c-b14e2aff3718"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 2., 2., 0., 0., 0., 0., 0., 1., 1., 2., 2., 2., 2., 0., 0.,\n",
              "       0., 1., 1., 1., 1., 0., 0., 0., 0., 2., 2., 2., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tEEtC6iZVtBB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}